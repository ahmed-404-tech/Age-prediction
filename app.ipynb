{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a4f98c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عدد الصور: 23708\n",
      "أول 5 صور: ['100_0_0_20170112213500903.jpg.chip.jpg', '100_0_0_20170112215240346.jpg.chip.jpg', '100_1_0_20170110183726390.jpg.chip.jpg', '100_1_0_20170112213001988.jpg.chip.jpg', '100_1_0_20170112213303693.jpg.chip.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = \"UTKFace\"\n",
    "if not os.path.isdir(folder):\n",
    "    raise FileNotFoundError(f\"File not found: {folder}\")\n",
    "\n",
    "all_files = sorted([f for f in os.listdir(folder) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "print(\"images count:\", len(all_files))\n",
    "print(\"first 5 images:\", all_files[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8825b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "إجمالي أعمار صالحة: 23700\n",
      "ملفات بايظة/غير صالحة: 8\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ages = []\n",
    "bad_files = []\n",
    "for file in all_files:\n",
    "    m = re.match(r'^(\\d+)', file) \n",
    "    if not m:\n",
    "        bad_files.append(file)\n",
    "        continue\n",
    "    age = int(m.group(1))\n",
    "    if age < 0 or age > 110:\n",
    "        bad_files.append(file)\n",
    "        continue\n",
    "    ages.append(age)\n",
    "\n",
    "print(\"toal age count:\", len(ages))\n",
    "print(\"bad age count:\", len(bad_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e83ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ عمر غير منطقي، تم تجاهل الملف: 111_1_0_20170120134646399.jpg.chip.jpg\n",
      "⚠ عمر غير منطقي، تم تجاهل الملف: 115_1_0_20170120134725990.jpg.chip.jpg\n",
      "⚠ عمر غير منطقي، تم تجاهل الملف: 115_1_0_20170120134725991.jpg.chip.jpg\n",
      "⚠ عمر غير منطقي، تم تجاهل الملف: 115_1_1_20170112213257263.jpg.chip.jpg\n",
      "⚠ عمر غير منطقي، تم تجاهل الملف: 116_1_0_20170112213001988.jpg.chip.jpg\n",
      "⚠ عمر غير منطقي، تم تجاهل الملف: 116_1_0_20170120134921760.jpg.chip.jpg\n",
      "⚠ عمر غير منطقي، تم تجاهل الملف: 116_1_2_20170112220255503.jpg.chip.jpg\n",
      "⚠ عمر غير منطقي، تم تجاهل الملف: 116_1_3_20170120134744096.jpg.chip.jpg\n",
      "شكل مصفوفة الصور: (23700, 64, 64, 3)\n",
      "عدد التسميات: (23700,)\n",
      "min age: 1.0 max age: 110.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for file in all_files:\n",
    "    path = os.path.join(folder, file)\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        print(\"bad image\", file)\n",
    "        continue\n",
    "\n",
    "    m = re.match(r'^(\\d+)', file)\n",
    "    if not m:\n",
    "        print(\"the file name is not a number\", file)\n",
    "        continue\n",
    "    age = int(m.group(1))\n",
    "    if age < 0 or age > 110:\n",
    "        print(\"age out of range\", file)\n",
    "        continue\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    images.append(img)         \n",
    "    labels.append(age)          \n",
    "\n",
    "images = np.array(images, dtype='uint8') \n",
    "labels = np.array(labels, dtype='float32')\n",
    "\n",
    "print(\"images shape:\", images.shape)\n",
    "print(\"labels shape:\", labels.shape)\n",
    "print(\"min age:\", labels.min(), \"max age:\", labels.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "age_bins = np.clip(labels // 10, 0, 10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=age_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025188e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255  \n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow(X_train, y_train, batch_size=32, shuffle=True)\n",
    "val_gen = val_datagen.flow(X_val, y_val, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7857ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential   \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.optimizers import Adam     \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fdbc979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(64,64,3)),\n",
    "    Conv2D(32,(3,3),padding='same',activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Conv2D(64,(3,3),padding='same',activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Conv2D(128,(3,3),padding='same',activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.35),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(1, activation='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='mean_absolute_error', \n",
    "              metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f577a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "checkpoint = ModelCheckpoint(\"best_age_model.keras\", save_best_only=True, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "27c06c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 349ms/step - loss: 18.2394 - mae: 18.2394 - val_loss: 18.2197 - val_mae: 18.2197 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 346ms/step - loss: 14.0397 - mae: 14.0397 - val_loss: 13.3105 - val_mae: 13.3105 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 339ms/step - loss: 13.3173 - mae: 13.3173 - val_loss: 12.3014 - val_mae: 12.3014 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 341ms/step - loss: 12.5425 - mae: 12.5425 - val_loss: 12.4991 - val_mae: 12.4991 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 326ms/step - loss: 11.8368 - mae: 11.8368 - val_loss: 15.4514 - val_mae: 15.4514 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 329ms/step - loss: 11.2904 - mae: 11.2904 - val_loss: 10.1788 - val_mae: 10.1788 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 334ms/step - loss: 10.9342 - mae: 10.9342 - val_loss: 13.1588 - val_mae: 13.1588 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 330ms/step - loss: 10.5590 - mae: 10.5590 - val_loss: 9.1156 - val_mae: 9.1156 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 331ms/step - loss: 10.3489 - mae: 10.3489 - val_loss: 9.3848 - val_mae: 9.3848 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 331ms/step - loss: 10.1882 - mae: 10.1882 - val_loss: 13.8649 - val_mae: 13.8649 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 10.1023 - mae: 10.1023\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 331ms/step - loss: 10.0017 - mae: 10.0017 - val_loss: 10.3213 - val_mae: 10.3213 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 339ms/step - loss: 9.7437 - mae: 9.7437 - val_loss: 10.1221 - val_mae: 10.1221 - learning_rate: 5.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 338ms/step - loss: 9.7001 - mae: 9.7001 - val_loss: 22.4976 - val_mae: 22.4976 - learning_rate: 5.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 9.6758 - mae: 9.6758\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 308ms/step - loss: 9.6190 - mae: 9.6190 - val_loss: 11.4711 - val_mae: 11.4711 - learning_rate: 5.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 308ms/step - loss: 9.4345 - mae: 9.4345 - val_loss: 8.7478 - val_mae: 8.7478 - learning_rate: 2.5000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 308ms/step - loss: 9.4197 - mae: 9.4197 - val_loss: 17.2761 - val_mae: 17.2761 - learning_rate: 2.5000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 308ms/step - loss: 9.3381 - mae: 9.3381 - val_loss: 20.5597 - val_mae: 20.5597 - learning_rate: 2.5000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 9.3065 - mae: 9.3065\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 312ms/step - loss: 9.3047 - mae: 9.3047 - val_loss: 9.8731 - val_mae: 9.8731 - learning_rate: 2.5000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 309ms/step - loss: 9.2317 - mae: 9.2317 - val_loss: 10.0594 - val_mae: 10.0594 - learning_rate: 1.2500e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 328ms/step - loss: 9.2774 - mae: 9.2774 - val_loss: 9.1947 - val_mae: 9.1947 - learning_rate: 1.2500e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 9.1221 - mae: 9.1221\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 326ms/step - loss: 9.1844 - mae: 9.1844 - val_loss: 9.4695 - val_mae: 9.4695 - learning_rate: 1.2500e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 327ms/step - loss: 9.1549 - mae: 9.1549 - val_loss: 8.0618 - val_mae: 8.0618 - learning_rate: 6.2500e-06\n",
      "Epoch 23/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 354ms/step - loss: 9.1139 - mae: 9.1139 - val_loss: 8.5559 - val_mae: 8.5559 - learning_rate: 6.2500e-06\n",
      "Epoch 24/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 331ms/step - loss: 9.1370 - mae: 9.1370 - val_loss: 8.3560 - val_mae: 8.3560 - learning_rate: 6.2500e-06\n",
      "Epoch 25/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 9.0951 - mae: 9.0951\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 331ms/step - loss: 9.1869 - mae: 9.1869 - val_loss: 9.5925 - val_mae: 9.5925 - learning_rate: 6.2500e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 333ms/step - loss: 9.1452 - mae: 9.1452 - val_loss: 9.2447 - val_mae: 9.2447 - learning_rate: 3.1250e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 326ms/step - loss: 9.1837 - mae: 9.1837 - val_loss: 8.8352 - val_mae: 8.8352 - learning_rate: 3.1250e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 9.1938 - mae: 9.1938\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 337ms/step - loss: 9.2092 - mae: 9.2092 - val_loss: 8.4944 - val_mae: 8.4944 - learning_rate: 3.1250e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 326ms/step - loss: 9.0849 - mae: 9.0849 - val_loss: 9.4121 - val_mae: 9.4121 - learning_rate: 1.5625e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 374ms/step - loss: 9.1437 - mae: 9.1437 - val_loss: 9.6914 - val_mae: 9.6914 - learning_rate: 1.5625e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=100,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca5cac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"age_predictor_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
